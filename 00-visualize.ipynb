{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8592dfb7",
   "metadata": {},
   "source": [
    "# Total Perspective Vortex\n",
    "- Date: `14-07-2023 3:30PM`\n",
    "- Third project in the AI branch of 42's system\n",
    "- Project description: \n",
    "    - `Learn to use python tools to process large dimension data, and create a man-machine interface thanks to brainwaves.`\n",
    "- Summary: \n",
    "    - `Brain computer interface with machine learning based on electoencephalographic data.`\n",
    "    - This subject aims to create a brain computer interface based on electroencephalographic\n",
    "data (EEG data) with the help of machine learning algorithms. Using a subject’s EEG\n",
    "reading, you’ll have to infer what he or she is thinking about or doing - (motion) A or B\n",
    "in a t0 to tn timeframe.\n",
    "- Goals:\n",
    "    - Process EEG datas (parsing and filtering)\n",
    "    - Implement a dimensionality reduction algorithm\n",
    "    - Use the pipeline object from scikit-learn\n",
    "    - Classify a data stream in \"real time\"\n",
    "\n",
    "  ##### Update 28th December 2023 - Continuing the ongoing work.\n",
    "    - Set up environment.\n",
    "    - Load data.\n",
    "    - Filter out bad frequencies.\n",
    "    - Analyze.\n",
    " \n",
    "  ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cd800-56d9-4087-be0f-e7cd095ef0df",
   "metadata": {},
   "source": [
    "# EEG (Electroencephalography)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8c0c1-2d1c-4f79-a624-bd26c2c20e1e",
   "metadata": {},
   "source": [
    "<img src=\"../assets/eeg-cover-intro.png\" alt=\"Intro image\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c4ed1-f70f-44da-8df9-7fde7a84d5ae",
   "metadata": {},
   "source": [
    "---\n",
    "## Steps:\n",
    "V.1 Preprocessing, parsing and formating . <br>\n",
    "V.2 Treatment pipeline . <br>\n",
    "V.3 Implementation . <br>\n",
    "V.4 Train, Validation and Test . <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ee2b5-b8d4-4034-b59e-2a705ef7455a",
   "metadata": {},
   "source": [
    "#### we pick data related to hands vs feet\n",
    "5, 9, 13 : Motor execution: hands vs feet (person executing the movement of his hands/feets for real)<br>\n",
    "6, 10, 14 : Motor imagery: hands vs feet (person imagine the movement of his hands/feets)<br>\n",
    "read: https://mne.tools/dev/generated/mne.datasets.eegbci.load_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a9e9b-c077-4e03-b8a6-05d3cfd5d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne import pick_types\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.preprocessing import ICA \n",
    "\n",
    "# DATA_SAMPLE_PATH = \"../data/\"\n",
    "mne.set_log_level(\"CRITICAL\")\n",
    "mne.set_config('MNE_BROWSE_RAW_SIZE','20,8')\n",
    "# CRITICAL ?? ---> check descripton bellow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507cf70-f1c5-488e-af19-1e95a2635c41",
   "metadata": {},
   "source": [
    "- **DEBUG:** Detailed information, typically useful for debugging.\n",
    "- **INFO:** General information about the program's progress.\n",
    "- **WARNING:** Indicates a potential issue that doesn't prevent the program from running.\n",
    "- **ERROR:** Indicates a more serious issue that may prevent certain functionality.\n",
    "- **CRITICAL:** Indicates a critical error that might lead to the program's termination.\n",
    "\n",
    "Setting the logging level to \"CRITICAL\" is often done when you want to minimize the amount of console output, especially when running scripts or programs in production environments where detailed logging may not be necessary.\n",
    "\n",
    "If you want more detailed logging information during development or debugging, you might use a higher logging level such as \"DEBUG\" or \"INFO.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbddc7-15fa-40e0-831e-73b2a537dd91",
   "metadata": {},
   "source": [
    "### Data loading:\n",
    "\n",
    "- The code loads EEG data for executing and imagining motor tasks for specified subjects and runs.<br>\n",
    "- For each subject and run combination, EEG data is loaded, and events corresponding to rest, foot movement, and hand movement are annotated.<br>\n",
    "- Annotations are created for both executing and imagining motor tasks, and the annotations are set to the respective raw data.<br>\n",
    "- The processed raw data is appended to the raw_files list.<br>\n",
    "- This code is designed for loading and preprocessing EEG data for motor task execution and imagery, making it ready for further analysis.<br>\n",
    "\n",
    "#### code details:\n",
    "- **`mne.events_from_annotations`**: extracts events from annotations in the raw EEG data.<br>\n",
    "It's applied separately to executing and imagining motor tasks.<br>\n",
    "The event_id parameter maps annotation labels to event codes.\n",
    "- **`mne.annotations_from_events`**: creates annotations from events.<br>\n",
    "It maps events to descriptions using the provided mapping.<br>\n",
    "Annotations include information about event timing and descriptions.\n",
    "    - ##### Parameters:\n",
    "        - `events`: Event array.\n",
    "        - `event_desc`: Dictionary mapping event codes to descriptions.\n",
    "        - `sfreq`: Sampling Frequency:<br>\n",
    "            - In the context of EEG data, the sfreq parameter stands for the \"sampling frequency\" of the raw data.<br>\n",
    "            - Sampling frequency represents the number of samples (data points) obtained per unit of time, usually expressed in Hertz (Hz).<br>\n",
    "            - For EEG data, the sampling frequency indicates how many samples are collected per second. Higher sampling frequencies provide more temporal detail but may require more storage and processing resources.<br>\n",
    "            - In this code, raw_execution.info['sfreq'] retrieves the sampling frequency from the information associated with the raw_execution object.\n",
    "        - `orig_time`: Original measurement time of the raw data.<br>\n",
    "            - The orig_time parameter represents the original measurement time of the raw EEG data.<br>\n",
    "            - It indicates the specific time point when the EEG recording began.<br>\n",
    "            - The information about the original measurement time is important for maintaining the temporal context of the EEG data.<br>\n",
    "            - In this code, raw_execution.info['meas_date'] retrieves the original measurement time from the information associated with the raw_execution object.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_print=print\n",
    "debug=True\n",
    "def print(*arg, **kwargs):\n",
    "\tif debug:\n",
    "\t\treal_print(*arg, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG Data Loading and Annotation\n",
    "\n",
    "# - T0 corresponds to rest\n",
    "# - T1 corresponds to the onset of motion (real or imagined) of the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "#   or both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "# - T2 corresponds to the onset of motion (real or imagined) of the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "#   or both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "\n",
    "subject = [1]  # List of subject numbers (e.g., [1, 4])\n",
    "run_execution = [5, 9, 13]  # Runs for executing motor tasks\n",
    "run_imagery = [6, 10, 14]  # Runs for imagining motor tasks\n",
    "\n",
    "raw_files = []\n",
    "\n",
    "# Loop through each subject and associated runs for execution and imagery\n",
    "debug=True\n",
    "for person_number in subject:\n",
    "    for i, j in zip(run_execution, run_imagery):\n",
    "        # Load EEG data for executing motor tasks\n",
    "        raw_files_execution = [read_raw_edf(f, preload=True, stim_channel='auto') for f in eegbci.load_data(person_number, i)]\n",
    "        print(f\"Raw files execution:{raw_files_execution}\")\n",
    "        raw_execution = concatenate_raws(raw_files_execution)\n",
    "        print(f\"Raw execution :{raw_execution}\")\n",
    "\n",
    "        # Load EEG data for imagining motor tasks\n",
    "        raw_files_imagery = [read_raw_edf(f, preload=True, stim_channel='auto') for f in eegbci.load_data(person_number, j)]\n",
    "        raw_imagery = concatenate_raws(raw_files_imagery)\n",
    "\n",
    "        # Extract events and create annotations for executing motor tasks\n",
    "        events, _ = mne.events_from_annotations(raw_execution, event_id=dict(T0=1, T1=2, T2=3))\n",
    "        print(f\"event :{events}\")\n",
    "        mapping = {1: 'rest', 2: 'do/feet', 3: 'do/hands'}\n",
    "        annot_from_events = mne.annotations_from_events(\n",
    "            events=events, event_desc=mapping, sfreq=raw_execution.info['sfreq'],\n",
    "            orig_time=raw_execution.info['meas_date'])\n",
    "        print(f\"annot_from_events :{annot_from_events}\")\n",
    "        debug=False\n",
    "        raw_execution.set_annotations(annot_from_events)\n",
    "\n",
    "        # Extract events and create annotations for imagining motor tasks\n",
    "        events, _ = mne.events_from_annotations(raw_imagery, event_id=dict(T0=1, T1=2, T2=3))\n",
    "        mapping = {1: 'rest', 2: 'imagine/feet', 3: 'imagine/hands'}\n",
    "        annot_from_events = mne.annotations_from_events(\n",
    "            events=events, event_desc=mapping, sfreq=raw_imagery.info['sfreq'],\n",
    "            orig_time=raw_imagery.info['meas_date'])\n",
    "        raw_imagery.set_annotations(annot_from_events)\n",
    "\n",
    "        # Append the processed raw data to the list\n",
    "        raw_files.append(raw_execution)\n",
    "        raw_files.append(raw_imagery)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = concatenate_raws(raw_files)\n",
    "originalRaw = raw.copy()\n",
    "events, event_dict = mne.events_from_annotations(raw)\n",
    "data = raw.get_data()\n",
    "\n",
    "# display(raw.info)\n",
    "print(len(events), event_dict)\n",
    "# display(raw.ch_names)\n",
    "# display(data)\n",
    "raw.plot(scalings=dict(eeg=1e-4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c031e-7305-4eff-a54b-799ad2f436af",
   "metadata": {},
   "source": [
    "### filter any bad channels that were identified to have artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162304c-0ad7-49a4-99d9-d650f7fd23ff",
   "metadata": {},
   "source": [
    "In MNE-Python, the `pick_types` function is used to select channels based on their types. The function returns indices of channels that match the specified criteria. The `pick_types` function takes several parameters to filter channels based on their types.\n",
    "\n",
    "- `raw.info`: This is the `info` attribute of the `raw` object, which contains information about the data, such as channel names, types, and other metadata.\n",
    "\n",
    "- `meg=False`: This specifies that MEG channels should not be included in the selection. Setting it to `False` means excluding MEG channels.\n",
    "  - MEG stands for Magnetoencephalography. MEG channels are sensors used in magnetoencephalography to measure the magnetic fields produced by neural activity in the brain. MEG is a non-invasive neuroimaging technique that complements other methods such as electroencephalography (EEG).\n",
    "\n",
    "- `eeg=True`: This specifies that EEG channels should be included in the selection. Setting it to `True` means including EEG channels.\n",
    "\n",
    "- `stim=False`: This specifies that stimulus channels should not be included in the selection. Setting it to `False` means excluding stimulus channels.\n",
    "  - A stimulus channel is a specific type of channel in EEG recordings that is dedicated to marking the timing of presented stimuli during an experiment. This channel typically contains events or triggers that indicate when a stimulus was presented to the participant. These events are essential for aligning EEG data with specific experimental conditions, allowing researchers to analyze and interpret the brain's response to different stimuli accurately.\n",
    "- `eog=False`: This specifies that EOG (electrooculogram) channels should not be included in the selection. Setting it to `False` means excluding EOG channels.\n",
    "    - specefic electrods placed around the eyes, to capture the nerve activities\n",
    "- `exclude='bads'`: This specifies that bad channels (channels marked as bad) should be excluded from the selection. Channels marked as bad are typically those with artifacts or other issues.\n",
    "\n",
    "After executing this line, the `picks` variable will contain the indices of EEG channels (excluding bad channels) from the `raw` object. These indices can be used to access or manipulate EEG data from the specified channels in subsequent steps of your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb37fae-75cc-4207-9de8-eb7353fc5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter any bad channels that were identified to have artifacts\n",
    "picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "print(picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe6805-121d-4443-9ace-2c24ccd6ccbe",
   "metadata": {},
   "source": [
    "## Standard montages\n",
    "**Standard Montage**: A standard montage defines the standardized positions of electrodes on the scalp. <br>\n",
    "Different standard montages provided by MNE-Python:\n",
    "- **'standard_1020'**: This is a standard EEG electrode montage with 21 electrodes based on the international 10-20 system.\n",
    "- **'standard_1005'**: Another standard EEG electrode montage with 348 electrodes based on the extended 10-05 system.\n",
    "- **'biosemi32'**: A BioSemi montage with 32 electrodes.\n",
    "- **'biosemi64'**: A BioSemi montage with 64 electrodes.\n",
    "\n",
    "**BioSemi** *is a company that specializes in the development and manufacturing of EEG (electroencephalogram) and other neurophysiological equipment. The BioSemi EEG system is a type of EEG recording system produced by BioSemi.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8aac23-e89b-4bea-881b-d0b8e25240fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_standard_montage('biosemi64').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e47b358-3973-418a-a817-0321442b5b6a",
   "metadata": {},
   "source": [
    "Sets the EEG channel names and applies a standard EEG montage, which includes digitization points for the EEG electrodes.\n",
    "\n",
    "This is a common and necessary step when working with EEG data in MNE-Python.\n",
    "\n",
    "- **`eegbci.standardize(raw)`**: This function is used to standardize the channel names of the EEG data. It ensures that the channel names follow a consistent naming convention, making it easier to work with standard montages.\n",
    "\n",
    "- **`make_standard_montage('standard_1005')`**: This function creates a standard EEG electrode montage based on the 10/05 system, which is a widely used electrode placement system. It defines the positions of EEG electrodes on the scalp.\n",
    "\n",
    "- **`raw.set_montage(montage)`**: This line sets the created electrode montage (montage) to the EEG data in the raw object. This step aligns the electrode positions in the data with the standard positions defined by 'standard_1005', facilitating accurate spatial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37aabb-8116-4991-b3f9-9866f7eb88e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eegbci.standardize(raw)  # set channel names\n",
    "biosemi_montage = make_standard_montage('standard_1005')\n",
    "raw.set_montage(biosemi_montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a7fe12-3ca2-4748-9ce9-0ae0c5fbb03d",
   "metadata": {},
   "source": [
    "---\n",
    "## Power Spectral Density (PSD)\n",
    "Plot the power spectral density (PSD) of the EEG data stored in the raw object. Here's what each line does:\n",
    "Power Spectral Density (PSD) just descrives the characteristics of time signals (RMS on Frequency range))\n",
    "- `raw.plot_psd(average=False)`: \n",
    "    - This line generates a plot of the power spectral density of the EEG data. \n",
    "    - The `average=False` argument means that it will plot the PSD separately for each channel rather than averaging across channels.\n",
    "\n",
    "#### ressources:\n",
    "- What is a power spectrum?: https://youtu.be/Gka11q5VfFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54624bfd-0f4e-4a60-b1f5-3e6746e9f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd();\n",
    "raw.plot_psd(average=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f161d7-ad4e-44ae-aa6c-6f32b3c64aca",
   "metadata": {},
   "source": [
    "#### In a power spectral density (PSD) plot for EEG data, the two dotted vertical lines pointing to a range between 5 and 20 Hz typically indicate the frequency range of interest, often referred to as a specific frequency band.\n",
    "\n",
    "The frequency range of interest in the context of EEG analysis typically includes the theta band (4-7 Hz), alpha band (8-13 Hz), beta band (13-30 Hz), and gamma band (30 Hz and above), with specific focus depending on the cognitive states or tasks under investigation.\n",
    "\n",
    "- **Theta Band (4-7 Hz)**: The lower dotted line around 5 Hz might represent the lower bound of the theta frequency band, associated with drowsiness, relaxation, and light sleep.\n",
    "\n",
    "- **Alpha Band (8-13 Hz)**: The upper dotted line around 20 Hz might represent the upper bound of the alpha frequency band, associated with a ***relaxed but awake state***. Alpha activity is often prominent when the ***eyes are closed***.\n",
    "\n",
    "- **Beta Band (13-30 Hz)**: The beta frequency band in EEG typically falls in the range of approximately 13 to 30 Hz. In a power spectral density (PSD) plot, you would expect the beta band to be situated between the alpha and gamma bands. It's often associated with active cognitive ***processing, concentration, and alertness***.\n",
    "\n",
    "- **Gamma Band (30-... Hz)** The gamma frequency range of approximately 30 Hz and above. Gamma oscillations are associated with ***high-frequency neural activity*** and are often linked to processes involving cognitive functions such as ***perception, attention, and memory encoding***.\n",
    "\n",
    "These frequency bands are commonly examined in EEG analysis to study different cognitive states and physiological phenomena. \n",
    "\n",
    "The vertical lines serve as a visual guide to highlight specific frequency ranges of interest on the PSD plot. \n",
    "\n",
    "Researchers often focus on these bands to analyze brain activity related to different mental states or tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be540c-5559-4acc-bea0-7ea3a9324e3e",
   "metadata": {},
   "source": [
    "## Notch Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283c653-c073-43c9-8a3c-a9cbe42d158c",
   "metadata": {},
   "source": [
    "**Notch Filter:** A specialized filter used in signal processing to selectively suppress or eliminate specific frequencies,\n",
    "\n",
    "often applied in EEG data processing to remove interference from power line noise at the frequency of the electrical power grid (e.g., 50 Hz or 60 Hz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0dd1b-a074-4c2a-a3f0-51d93a942394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notch filter\n",
    "notch_freq = 60\n",
    "raw.notch_filter(notch_freq, fir_design='firwin')\n",
    "raw.compute_psd().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29b071-5e13-4d06-a367-4fc13b2f7dd4",
   "metadata": {},
   "source": [
    "## Band-Pass filter to EEG data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80538ebe-0d96-4e07-beb4-b436dcc3e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band-pass filter keep only alpha and beta waves\n",
    "low_cutoff = 8\n",
    "high_cutoff = 30\n",
    "raw.filter(low_cutoff, high_cutoff, fir_design='firwin')\n",
    "raw.compute_psd().plot()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263e5bf-725a-4cc4-a4b3-dd08cdf79710",
   "metadata": {},
   "source": [
    "## Final result with basic filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3dd44-c2b8-42c0-a633-a3107bbe4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalRaw.compute_psd().plot()\n",
    "raw.compute_psd().plot()\n",
    ";\n",
    "originalRaw.compute_psd().plot(average=True)\n",
    "raw.compute_psd().plot(average=True)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808be0d-effc-4be9-b965-91e6fa699a75",
   "metadata": {},
   "source": [
    "## Events\n",
    "\n",
    "\n",
    "1. `fig = mne.viz.plot_events(events, sfreq=raw.info['sfreq'], first_samp=raw.first_samp, event_id=event_dict)`: This line generates an event plot using MNE-Python's `plot_events` function. It visualizes the occurrence and types of events in the EEG data.\n",
    "\n",
    "   - `events`: This is a NumPy array containing event information, typically obtained from an event file associated with the EEG recording.\n",
    "   - `sfreq=raw.info['sfreq']`: Specifies the sampling frequency of the EEG data, which is extracted from the information stored in the `raw` object.\n",
    "   - `first_samp=raw.first_samp`: Specifies the index of the first sample in the raw data. It ensures correct alignment of events with the EEG data.\n",
    "   - `event_id=event_dict`: Specifies a dictionary mapping event labels to event codes. This helps in labeling different types of events in the plot.\n",
    "\n",
    "2. `fig.subplots_adjust(right=0.7)`: This line adjusts the layout of the subplots in the figure, specifically expanding the space on the right side of the plot. It's often used to make room for legend annotations or additional information.\n",
    "\n",
    "In summary, these lines create an event plot for EEG data, displaying the timing and types of events, and adjust the layout of the plot to accommodate additional information on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f062b-dcc2-4c83-ae09-1e1e75399dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\":- events shape = \", events.shape)\n",
    "print(\":- raw.info['sfreq'] = \", raw.info['sfreq'])\n",
    "print(\":- first_samp = \", raw.first_samp)\n",
    "print(\":- event_id = \", event_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66018e8-d0e8-4356-a323-c121f941e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mne.viz.plot_events(events, sfreq=raw.info['sfreq'], first_samp=raw.first_samp, event_id=event_dict)\n",
    "# fig.subplots_adjust(right=0.7)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8447394-3d2a-49c1-a59d-bdcba52d42ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eae980-86c2-4702-9ed1-c98267bbf13a",
   "metadata": {},
   "source": [
    "##  Independent Component Analysis (ICA) \n",
    "إستأصال الترددات المتداخلة مع الدماغ عن طريق التعلم العميق للالة المعد مسبفا \n",
    "\n",
    "##### perform Independent Component Analysis (ICA) on EEG data to identify and visualize independent components. \n",
    "##### It specifically focuses on identifying components related to eye movements (EOG artifacts) and prints the indices of the identified \"bad\" components. \n",
    "##### These components can then be excluded from further analysis or removed from the data to enhance the quality of EEG recordings.\n",
    "- `rawClone = raw.copy()`: This line creates a copy of the raw EEG data. The raw object is typically an instance of the mne.io.Raw class representing continuous EEG data. Creating a copy (rawClone) is a common practice to avoid modifying the original data during processing.\n",
    "- `ica = ICA(n_components=20, method='fastica', random_state=97)`: This line initializes an Independent Component Analysis (ICA) object. ICA is a technique used for blind source separation and is commonly applied to EEG data to identify and remove artifacts. The parameters specified include:\n",
    "    - `n_components=20`: Specifies the number of independent components to estimate. In this case, it's set to 20.\n",
    "      - explanation:\n",
    "        - indicates that you are requesting the ICA algorithm to identify and separate the EEG data into 20 independent components. Each independent component represents a linear combination of the original EEG channels, capturing different sources of neural or non-neural activity.\n",
    "        - Choosing the appropriate number of components is a crucial step in ICA. If the number is too low, you may not capture all relevant sources in the data. If it's too high, you might end up with components that represent noise or overfit the data.\n",
    "        - In practice, determining the optimal number of components often involves exploring the data and using domain knowledge or statistical criteria to guide the selection. Researchers might assess the explained variance, examine the topographic maps of the components, or use other metrics to guide the choice of n_components based on the characteristics of the EEG data and the goals of the analysis.\n",
    "\n",
    "    - `method='fastica'`: Specifies the ICA algorithm to use. 'fastica' is a commonly used algorithm for EEG artifact removal.\n",
    "    - `random_state=97`: Sets the random seed for reproducibility. The same seed ensures that the results are consistent across runs.\n",
    "- `ica.fit(rawClone, picks=picks)`: This line fits the ICA model to the EEG data (rawClone). The picks parameter is used to specify the subset of channels on which to perform the ICA. It's a good practice to limit the ICA to relevant channels, often excluding certain channels like EOG (electrooculogram) or other non-EEG channels.\n",
    "\n",
    "- `ica.plot_components()`: This line generates a plot of the independent components estimated by the ICA. The purpose of this plot is to visually inspect the components and identify those that correspond to artifacts (such as eye blinks, muscle activity) as opposed to neural sources.\n",
    "\n",
    "- `eog_indicies, scores= ica.find_bads_eog(raw, ch_name='Fpz', threshold=1.5)`: This line identifies \"bad\" independent components that likely represent artifacts related to eye movements. It uses the find_bads_eog method, which leverages information about the EOG channels ('Fpz' in this case) to identify components associated with eye movements. The threshold parameter determines the sensitivity of the algorithm.\n",
    "\n",
    "- `print(\"Bad indicies: \" + str(eog_indicies))`: This line prints the indices of the identified \"bad\" independent components. These components can be further inspected and potentially removed from the EEG data to improve data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd93ecf-3a9e-49f4-8942-174e95eaa23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corrected = raw.copy()\n",
    "n_components = 20\n",
    "\n",
    "ica = ICA(n_components=20, method='fastica', fit_params=None, random_state=97)\n",
    "\n",
    "ica.fit(raw_corrected, picks=picks)\n",
    "\n",
    "ica.plot_components()\n",
    "\n",
    "eog_indicies, scores= ica.find_bads_eog(raw, ch_name='Fpz', threshold=1.5)\n",
    "print(\"eog_indicies: \", eog_indicies)\n",
    "ica.plot_scores(scores, exclude=eog_indicies)\n",
    "ica.exclude.extend(eog_indicies)\n",
    "raw_corrected = ica.apply(raw_corrected, n_pca_components = n_components, exclude = ica.exclude)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed3939-930c-4269-b9ff-020e8d62f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(raw)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ebdb6-d82a-4ebd-8225-72a9de940a8e",
   "metadata": {},
   "source": [
    "## Before / After all filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf511b-ed8b-4c11-bc63-8f89e9de9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalRaw.plot(scalings=dict(eeg=1e-4))\n",
    "raw.plot(scalings=dict(eeg=1e-4))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b02c6-e4e5-4a7d-9d0b-a51bdb4355a9",
   "metadata": {},
   "source": [
    "## Plot 30 channel output during 100 seconds before and after the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf96ad-0510-42a5-8af7-785fc54a9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of channels:\", len(raw.ch_names))\n",
    "print(\"Total duration:\", raw.times[-1], \"seconds\")\n",
    "originalRaw.plot(n_channels=30, start=0, duration=100, scalings=dict(eeg=250e-6))\n",
    "raw.plot(n_channels=30, start=0, duration=100, scalings=dict(eeg=200e-6))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0384e-2aa8-4f99-8471-b098d71776f8",
   "metadata": {},
   "source": [
    "## Before and After:\n",
    "### demo with 3 channels only, for clear plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953b1fb-0df4-4ae9-ba39-087fb5f32204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalRaw.plot(n_channels=3, scalings=dict(eeg=250e-6))\n",
    "originalRaw.plot(n_channels=3, start=0, duration=40, scalings=dict(eeg=250e-6))\n",
    "raw.plot(n_channels=3, start=0, duration=40, scalings=dict(eeg=250e-6))\n",
    "\n",
    "# raw.plot(n_channels=5, start=0, duration=40, scalings=dict(eeg=250e-6))\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424fcf2-1dde-4595-9566-f9f711d586d1",
   "metadata": {},
   "source": [
    "## Share Data with other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b36f6d-b9ec-4f59-ba16-a87dcfc89841",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pickleshare\n",
    "# Notebook 1\n",
    "from pickleshare import PickleShareDB\n",
    "db = PickleShareDB('./tmp')\n",
    "db['raw'] = raw\n",
    "db['originalRaw'] = originalRaw\n",
    "db['picks'] = picks\n",
    "db['events'] = events\n",
    "db['evens'] = events\n",
    "db['events_ids'] = event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fba6b3-70e6-45f3-992e-0cc0249f3511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TPV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
